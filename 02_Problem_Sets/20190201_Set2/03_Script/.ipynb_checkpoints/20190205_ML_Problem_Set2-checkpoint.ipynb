{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Problem Set 2\n",
    "### Simulations\n",
    "\n",
    "#### Problem 7\n",
    "\n",
    "Write a program that generates training data of $n$ i.i.d pairs $D _ { n } = \\left\\{ \\left( X _ { 1 } , Y _ { 1 } \\right) , \\ldots , \\left( X _ { n } , Y _ { n } \\right) \\right\\}$ of random variables where $X$ takes values in  $\\mathbb { R } ^ { d }$ and $Y \\in \\{ 0,1 \\}$. The joint distribution is such that $X$ is uniformily distributed in $[ 0,1 ] ^ { d }$ and $\\mathbf { P } \\{ Y = 1 | X = x \\} = x ^ { ( 1 ) }$ where $x ^ { ( 1 ) }$ is the first component of $x = \\left( x ^ { ( 1 ) } , \\ldots , x ^ { ( d ) } \\right)$ \n",
    "\n",
    "Classify $X$ using 1,2,5,7,9-nearest neighbor rules. Re-draw $(X,Y)$ many times so that you can estimate the risk of these rules.  Try this for various values of $n$ and $d$ and plot the estimated risk. Explain what you observe. \n",
    "\n",
    "Then consider the classification rule that uses an additional set of $m$ independent data $D _ { m } ^ { \\prime } = \\left\\{ \\left( X _ { 1 } ^ { \\prime } , Y _ { 1 } ^ { \\prime } \\right) , \\ldots , \\left( X _ { m } ^ { \\prime } , Y _ { m } ^ { \\prime } \\right) \\right\\}$ drawn from the same distribution to select the value of $k \\in \\{ 1,3,5,7,9 \\}$ in the $k$-nearest neighbot rule (trained on the data $D_n$) using empirical risk minimization based on $D _ { m } ^ { \\prime }$. Estimate the probability of error of this rule (using independent test data) and compare it to the probability of error of the best of these five classification rules. How large does $m$ have to be to make sure that the data/based selection is close to optimal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import itertools\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DGP we need to generate (X,y) pairs, since sklearn-knn uses knn.fit(X,y) to \"fit\" the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Generation\n",
    "def generate_data(n,d):\n",
    "    X = np.random.uniform(0,1,n*d).reshape(n,d)\n",
    "    \n",
    "    # Random version\n",
    "    y = [np.random.binomial(1,p=x[0]) for x in X]\n",
    "    \n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bayes_classifier:\n",
    "    \n",
    "    def __init__(self,boundary):\n",
    "        self.boundary = boundary\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "        \n",
    "    def predict(self,X):\n",
    "        prediction = [1 if x[0] >= self.boundary else 0 for x in X ]\n",
    "        return(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifiers\n",
    "bayes = bayes_classifier(boundary= 0.5)\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=2)\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn7 = KNeighborsClassifier(n_neighbors=7)\n",
    "knn9 = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "classifiers = [bayes, knn1, knn2, knn5, knn7, knn9]\n",
    "\n",
    "classifier_names = ['Bayes','1-NN', '2-NN', '5-NN', '7-NN', '9-NN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now estimate the risk of each classifier. The empirical risk is defined as \n",
    "\n",
    "$$R_n(g) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{1}_{g(x) \\neq y}$$\n",
    "\n",
    "which is nothing more than one minus the accuracy. (Should be on the training set, use cross validation?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying sample sizes\n",
    "sample_sizes = np.arange(500,1000,20)\n",
    "\n",
    "# Dimensions\n",
    "dims_to_plot = [[2,5],[10,100]]\n",
    "\n",
    "\n",
    "# Rounds per sample size\n",
    "rounds = 500\n",
    "\n",
    "# Testing size\n",
    "testing_n = 500\n",
    "\n",
    "# Setting up colors for the plot\n",
    "colors = sns.color_palette(\"RdBu\",n_colors=len(classifiers))\n",
    "\n",
    "for dimensions in dims_to_plot:\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(20,10))\n",
    "\n",
    "    for i in range(0,len(dimensions)):\n",
    "        \n",
    "        # Current Dimension\n",
    "        d = dimensions[i]\n",
    "        \n",
    "        # Array for storing accuracy scores per dimension.\n",
    "        accuracy = np.array([], dtype=np.int64).reshape(0,len(classifiers))\n",
    "    \n",
    "        for n in sample_sizes:\n",
    "    \n",
    "            accuracy_temp = []\n",
    "    \n",
    "            for r in range(rounds):\n",
    "    \n",
    "                # Temporary arry for accuracy\n",
    "                temp = []\n",
    "    \n",
    "                # \"Training\" data on which we fit on\n",
    "                X, y = generate_data(n,d)\n",
    "\n",
    "                # Generate larger sample on which we get our accuracy\n",
    "                testing_X, testing_y = generate_data(testing_n,d)\n",
    "            \n",
    "                for classifier in classifiers:\n",
    "            \n",
    "                    classifier.fit(X,y)\n",
    "    \n",
    "                    predictions = classifier.predict(testing_X)\n",
    "    \n",
    "                    temp.append(1-accuracy_score(testing_y,predictions))\n",
    "        \n",
    "                accuracy_temp.append(temp)\n",
    "        \n",
    "            mean_accuracy = np.mean(accuracy_temp,axis=0)\n",
    "        \n",
    "            accuracy = np.concatenate((accuracy,[mean_accuracy]), axis = 0)\n",
    "    \n",
    "        for j in range(0,len(classifiers)):\n",
    "            sns.lineplot(x= sample_sizes, y =accuracy[:,j], ax= ax[i], color = colors[j])\n",
    "            ax[i].set_title(f\"d={dimensions[i]}\",fontsize = 18,fontweight = 100)\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_xlabel(\"Sample Size\",fontsize=15)\n",
    "        a.set_ylabel(\"$R_n(g)$\",fontsize=15)\n",
    "    \n",
    "    \n",
    "    fig.legend(classifier_names,frameon=False,\n",
    "               fontsize = 15,loc = 8,ncol = len(classifiers))\n",
    "            \n",
    "    fig.suptitle(\"Empirical Risk of k-NN classifiers\",fontsize = 20);\n",
    "    fig.savefig(f\"../01_Figures/Emp_Risk_KNN_largeN_d_{dimensions[0]}_{dimensions[1]}\", dpi=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the classification rule that uses and additional set of $m$ independent data $D _ { m } ^ { \\prime } = \\left\\{ \\left( X _ { 1 } ^ { \\prime } , Y _ { 1 } ^ { \\prime } \\right) , \\ldots , \\left( X _ { m } ^ { \\prime } , Y _ { m } ^ { \\prime } \\right) \\right\\}$ drawn from the same distribution to select the value of $k \\in \\{ 1,3,5,7,9 \\}$. Train the data on $D_n$ and select the classifier based on empirical risk minimization on the set $D_m$.  Finally draw many new samples to get the out of sample risk of the final classifier.  How large does $m$ have to be to make sure that the databased selection is close to optimal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.32538234098\n",
    "np.round(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(n,d,rounds,testing_n,validation_sizes):\n",
    "    \n",
    "    # Define Classifiers\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn2 = KNeighborsClassifier(n_neighbors=2)\n",
    "    knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn7 = KNeighborsClassifier(n_neighbors=7)\n",
    "    knn9 = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "    # Store in list to loop over\n",
    "    classifiers = [knn1, knn2, knn5, knn7, knn9]\n",
    "\n",
    "    # Set up for plot and storing results\n",
    "    classifier_names = ['1-NN', '2-NN', '5-NN', '7-NN', '9-NN']\n",
    "    \n",
    "    # Dataframe for storing the results\n",
    "    columns_df = classifier_names + ['Risk CV', 'Risk 9-NN']\n",
    "    results = pd.DataFrame(np.nan, index=validation_sizes, columns= columns_df)\n",
    "\n",
    "    # Results to plot\n",
    "    to_plot1 = [\"Risk CV\",'Risk 9-NN']\n",
    "    to_plot2 = ['1-NN', '2-NN', '5-NN', '7-NN', '9-NN']\n",
    "\n",
    "    # Simulation\n",
    "    for m in validation_sizes:\n",
    "        \n",
    "        # Array to store risk at point m\n",
    "        m_temp = []\n",
    "    \n",
    "        # Array to store risk of 9-nn classifier\n",
    "        knn9_risk = []\n",
    "    \n",
    "        # Choosen classifier\n",
    "        choosen_Classifier = []\n",
    "    \n",
    "        for r in range(rounds):\n",
    "\n",
    "            # Draw data n (training data)\n",
    "            X_n, y_n = generate_data(n,d)\n",
    "\n",
    "            # Draw data m (validation data)\n",
    "            X_m, y_m = generate_data(m,d)\n",
    "\n",
    "            # Final testing data\n",
    "            testing_X, testing_y = generate_data(testing_n,d)\n",
    "\n",
    "            # Temp to store risk -> For later choosing min risk classifier\n",
    "            temp = []\n",
    "\n",
    "            for classifier in classifiers:\n",
    "    \n",
    "                # Fit on training set X_n, y_n\n",
    "                classifier.fit(X_n,y_n)\n",
    "    \n",
    "                # Get score on testing set X_m, y_m\n",
    "                temp.append(1-classifier.score(X_m,y_m))\n",
    "    \n",
    "            # Choose minimum risk classifier based on out of sample risk minimization\n",
    "            classifierCv = classifiers[temp.index(min(temp))]\n",
    "\n",
    "            # Store name of the choice \n",
    "            choosen_Classifier.append(classifier_names[temp.index(min(temp))])\n",
    "\n",
    "            # Estimate risk of the rule based on the independent test data\n",
    "            m_temp.append(1-classifierCv.score(testing_X,testing_y))\n",
    "        \n",
    "            # Same for 9-nn for comparing as optimum\n",
    "            knn9.fit(X_n,y_n)\n",
    "        \n",
    "            knn9_risk.append(1-knn9.score(testing_X,testing_y))\n",
    "        \n",
    "        # Count choices  \n",
    "        m_result =  [choosen_Classifier.count(knn)/rounds for knn in classifier_names]\n",
    "    \n",
    "        # Append other results\n",
    "        m_result.extend((np.round(np.mean(m_temp),2),np.round(np.mean(knn9_risk),2))\n",
    "    \n",
    "        # Store results in df \n",
    "        results.loc[m,:] = m_result \n",
    "\n",
    "    # Plot the results for current values\n",
    "    fig, ax = plt.subplots(nrows= 1, ncols=2,figsize=(20,10))\n",
    "\n",
    "    # Risk of cross-validation rule and 9-nn\n",
    "    sns.lineplot(data=results[to_plot1], palette= \"RdBu\", dashes =  False,ax=ax[0])\n",
    "    ax[0].legend(to_plot1,frameon=True, fontsize = 15,loc = 1,ncol = len(to_plot1))\n",
    "    ax[0].set_title(\"Risk of Rule Based Classifier and 9-NN\",fontsize = 18,fontweight = 100)\n",
    "    ax[0].set_ylabel(\"$R_n(g)$\",fontsize=15)\n",
    "\n",
    "\n",
    "    # Choices as percent of rounds \n",
    "    sns.lineplot(data =results[to_plot2], palette= \"RdBu\", dashes=False, ax= ax[1])\n",
    "    ax[1].legend(to_plot2,frameon=True, fontsize = 14,loc = 1,ncol = len(to_plot2))\n",
    "    ax[1].set_title(\"Choice of k in Rule Based Classifier\",fontsize = 18,fontweight = 100)\n",
    "    ax[1].set_ylabel(\"Frequency of Choice of Classifier\", fontsize = 15)\n",
    "    \n",
    "    for a in ax:\n",
    "        a.set_xlabel(\"Validation Size $m$\",fontsize=15)\n",
    "    \n",
    "    fig.suptitle(f\"$D_n$ = {n}, Dimension = {d}\",fontsize = 20);\n",
    "    fig.savefig(f\"../01_Figures/CV_KNN_n{n}_d{d}\", dpi=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "simulate(n=500,d=10,rounds =500,testing_n=500,validation_sizes=np.arange(20,500,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate in parallel\n",
    "\n",
    "# Simulation rounds\n",
    "rounds = 1000\n",
    "\n",
    "# set sample sizes and dimensions to simulate\n",
    "sample_sizes_n = [100,500,1000]\n",
    "dimensions = [2,10,100]\n",
    "\n",
    "# Combine the two to iterate over\n",
    "combinations = list(itertools.product(sample_sizes_n, dimensions))\n",
    "\n",
    "# Sizes of the cross validation sample\n",
    "validation_sizes = np.arange(100,2000,50)\n",
    "\n",
    "# Sample size for indenpendent testing sample \n",
    "testing_n = 500\n",
    "\n",
    "# Execute in Parallel\n",
    "pool = Pool(processes=4)\n",
    "\n",
    "# Submit jobs in parallel\n",
    "results = [pool.apply_async(simulate, args=(comb[0],comb[1],rounds,testing_n,validation_sizes)) for comb in combinations]\n",
    "\n",
    "output = [p.get() for p in results]\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "632px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
