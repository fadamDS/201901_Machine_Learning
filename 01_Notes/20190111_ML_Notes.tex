\documentclass[12pt, authoryear]{elsarticle}
\makeatletter
\def\ps@pprintTitle{%
	\let\@oddhead\@empty
	\let\@evenhead\@empty
	\def\@oddfoot{}%
	\let\@evenfoot\@oddfoot}
\makeatother
%\usepackage{lmodern}
% My spacing
\usepackage{setspace}
\setstretch{1.5}

%\DeclareMathSizes{12}{14}{10}{10}
\usepackage[margin=2.5cm]{geometry}    % How to set margins - optimized for 2.5cm      

% See geometry.pdf to learn the layout options. There are lots.
\geometry{a4paper}                   			% ... or a4paper or a5paper or ... 
\usepackage{enumitem}
\usepackage{mathtools}
%\geometry{landscape}                		% Activate for rotated page geometry
\usepackage[parfill]{parskip}    			% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}						% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
% TeX will automatically convert eps --> pdf in pdflatex	
\usepackage{flafter}			
\usepackage{setspace}
%\linespread{1.5}
\usepackage[font={}]{caption}
\usepackage[bottom]{footmisc}
\usepackage[capposition=top]{floatrow}   %figure notes

%math packages 
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{graphicx,epsf,subfigure}
\usepackage{pstricks,pst-node,psfrag}
\usepackage{amsthm,amssymb,amsmath}
\usepackage{amsmath,bm}
\usepackage{amsmath}

%mathnotes
\newcommand{\bbeta}{\mbox{\boldmath $\beta$}}
\newcommand{\beps}{\mbox{\boldmath $\epsilon$}}
\newcommand{\bX}{\mbox{\boldmath $X$}}
\newcommand{\bY}{\mbox{\boldmath $Y$}}
\newcommand{\bI}{\mbox{\boldmath $I$}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\x}{\textsc{\textbf{x}}}
\newcommand{\xx}{\textsc{x}}

%add figure 
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{hyperref}
\usepackage[round]{natbib}

\usepackage{soul}

\def\bibsection{\section{References}} %%% Make "References" appear before bibliography
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{tablefootnote}
\usepackage{lscape} 
\usepackage{animate}
\usepackage{bbm}

\renewcommand{\contentsname}{Table of Contents} % change name from Contents to Table of Contents

\usepackage{titlesec}

\setcounter{secnumdepth}{4}

%_______________________________________________________________________________________________________%
%_______________________________________________________________________________________________________%
%\usepackage[table]{xcolor}% http://ctan.org/pkg/xcolor
%\usepackage{graphicx,multirow}
\usepackage{xcolor,colortbl}
\usepackage{xcolor}
%\usepackage{graphicx,multirow}
\usepackage[capposition=top]{floatrow}
\setcounter{secnumdepth}{4}

\begin{document}

\begin{frontmatter}  %

\title{Lecture Notes Machine Learning}

\author[Add1]{Felix Adam}
\ead{felix.adam@bracelonagse.eu}

\address[Add1]{Barcelona Graduate School of Economics, Barcelona, Spain}
%\address[Add2]{Some other Institution, Cape Town, South Africa}

%\cortext[cor]{Corresponding author: Nico Katzke}

\begin{abstract}
\small{
This document contains my lecture notes for the course Machine Learning at the Barcelona Graduate School of Economics 
}
\end{abstract}

\vspace{1cm}


\vspace{0.5cm}
\end{frontmatter}

\headsep 35pt % So that header does not go over title

\section{Introduction} \label{introduction}
The main goal of this course is to develop an understanding for the reasons why certain machine learning algorithms work. Interestingly, some modern methods, such as Deep Learning, are not fully understood. It is not clear why these methods work or theory even says they shouldn't be as succesful. 


We will start with discussing basic concentration inequalities, followed up by simple mean estimation. After that we'll start discussing supervised learning problems, mostly focused on classification with a minor detour towards regression. We then dive into the topic of empirical risk minimization and VC-theory. This will be followed by a discussion of linear classification, mostly support vector machines and kernel methods. Following, we transition to non-linear methods, especially classification trees and random forests. We finish the course with a discussion of clustering, spectral clustering and k-means and finally online-learning. 

\section{Mean Estimation} \label{mean_estimation}

\subsection{Motivation}

We start the course with a seemingly simple task: estimating the mean of a population, given a sample drawn from the population.

The simplest considerable problem is to consider a setting where we are given independent, identically distributed (i.i.d) draws $X_1, X_2, ... , X_n$ of real-valued random variables. We further assume, that the mean (the expected value) exists $E[X] = m$. (Note that not all distributions have an expected value, such as the cauchy distribution).

Our goal is now, to find an estimate of $m$, based on the observed data. 

An estimator is a function $m_n : \mathbb{R}^n \rightarrow \mathbb{R}$ that maps inputs to a value. We denote our estimate of the mean as the output of the function given the data $m_n(X_1, X_2, ..., X_n) = m_n$ (Note that the value of the estimate is commonly also denoted as $m_n$. 

It is important to realize, that $m_n$ is a function of random variables, so naturally, $m_n$ is also a random variable. Ultimately, we would like to have an estimate (i.e., a data-based quantity) $m_n$ that is close to the real mean $m$. We now need to figure out what "close" means.

\subsection{Measuring the Error}

A possible, and common way to measure the error is through the mean squared error (MSE)

$$ \text{MSE} = E[(m_n - m ) ^2]$$

(Some terminology: The MSE is the risk of the estimator $m_n$ under the squared loss.) However, the MSE is not the only possible measure of "closeness". Others are:

\begin{itemize}
\item Expected absolute error: $E[|m_n -m|]$
\item Using probabilities: $P(|m_n - m| > \epsilon) $
\end{itemize}

We can also discuss the closeness in terms of loss functions $l: \mathbb{R} \rightarrow [0, \infty)$. The corresponding risk is the expected loss $E[l(m_n -m)]$.
The loss functions associated with the discussed errors are:

\begin{itemize}
\item MSE: $l(x) = x^2$
\item Absolute error: $l(x) = |x|$
\item Probability : $l(x) = \mathbbm{1}_{|x|>\epsilon}$
\end{itemize}

These criteria of closeness are not the same! So in order to assess an estimator, we first have to set a goal, in which sense do we want the estimator to be "good". 

\subsection{A simple Estimator}

The most natural mean estimator is the \textbf{empirical mean}.

$$ \overline{m_n} = \frac{1}{n} \sum_{i=1}^{n} X_i $$

By the law of large numberers, as the sample size increases, the probability that the sample mean is equal to the true mean converges to 1. 

Further, the sample mean is an unbiased estimate of the true mean, since:

$$E[m_n] =  E[\frac{1}{n} \sum_{i=1}^{n} X_i] = \frac{1}{n}\sum_{i=1}^{n} E[X_i] = m$$

(By the linearity of expectations). 

We can now derive the MSE of the sample mean. Since we've shown that the estimator is unbiased, the MSE is the variance of the mean estimator. 


\begin{equation*} 
\begin{split}
E[(m_n -m)^2] & = E[(\frac{1}{n} \sum_{i=1}^{n}X_i -m)^2] = \text{var}(m_n) = \text{var}(\frac{1}{n} \sum_{i=1}^{n}X_i) \\ 
&= \frac{1}{n^2} \text{var}(\sum_{i=1}^{n} X_i) = \frac{\sigma^2}{n}
\end{split}
\end{equation*}

(By the linearity of the variance of independent random variables.)
Note that this is only meaningful of the variance is $\sigma^2$ is fininte. Otherwise the MSE is also infinite. 

What does this formula suggest? The error $|m_n - m |$ is typically of the order of $\frac{\sigma}{\sqrt{n}}$. This can be derived from the following observation:

We know from the properties of the variance (not smaller than 0) that:

$$(E[X])^2 \leq E[X^2]$$ 

since $\text{Var}(X) = E[X^2] - (E[X])^2$. From this follows, that $E[X] \leq \sqrt{E[X^2]}$ and thus

$$ E[|m_n -m |] \leq \sqrt{E[m_n - m)^2]} = \frac{\sigma}{\sqrt{n}}$$

Thus, we've established a first bound for the MSE of the sample mean. We can say that the expected distance between the sample mean and the true mean depends on the variance and the sample size.

Very often one needs control probabilities of the type 

$$P(|m_n - m| > \epsilon) $$

This will especially be important when wee need to estimate the mean of not just one but many random variables say $N$ of them and we want to make sure that the errors are simultaneously small. In other words, we need to control 

$$max | m_n^{(j)} - m^{(j)}|$$ 

In order to deal with these types of probabilities and find proper bounds, we'll need to establish some common inequalities.

\subsection{Inequalities for sums of indenpendent random variables}

\subsubsection{Markov's Inequality} \label{markov_ineq}

We start with the Markov inequality. The inequality yields an upper bound for the probability that a random variable $X$ exceeds a given value $t$. We are using the special case of the Markov inequality where $X \geq 0$. Then

$$ P(X \geq t) \leq \frac{E[x]}{t}$$

\underline{Proof}

Let $\mathbbm{1}_t$ be the indicator function that event $t$ occurs.  We have $\mathbbm{1}_{(X \geq t)} = 1$ if $X \geq t$ and $\mathbbm{1}_{(X \leq t)} = 0$ otherwise. Then given that $t > 0$ we find

$$ t \mathbbm{1}_{(X \geq t)} = X $$

since if $X < t$ then $\mathbbm{1}_{(X \leq t)} = 0$ and so $t \mathbbm{1}_{( X > t ) } = 0 \leq X$. Othweise, if$X \geq t$, we have $\mathbbm{1}_{(X \leq t)} = 1$ and thus $t \mathbbm{1}_{( X > t ) } = t \leq X$. Taking the expecations on both sides:

$$ E[t \mathbbm{1}_{(X \geq t)}  \leq E[X] $$

using 

$$ t E[\mathbbm{1}_{(X \geq t)}] = a ( 1 \cdot \mathrm { P } ( X \geq t ) + 0 \cdot \mathrm { P } ( X < t ) ) = t \mathrm { P } ( X \geq t )$$

Thus we have

$$ t P(X \geq t) \leq E[X] $$

\subsubsection{Chebyshev's Inequality} \label{chebyshev}

Chebyshev's inequality bounds the probability that a random variable deviates from it's expected value by more than a given threshold by the variance of the random variable itself. 

$$ P(| X - E[X] | \geq t) \leq \frac{\text{Var}(X)}{t^2}$$

\underline{Proof}

The proof can be derived by using Markov's inequality and by transforming the inequality through taking the square.

$$ P( | X- E[X] | \geq t) = P( (X - E[X] )^2 \geq t^2) \leq \frac{(E[X - E[X])^2}{t^2} = \frac{\text{Var}(X)}{t^2}$$

In particular, for the sample mean we find:

$$ P(| m_n - m | \geq \epsilon) \leq \frac{\text{Var}(m_n)}{t^2} = \frac{\sigma^2}{n\epsilon^2} $$

This implies the weak law of large numbers. The probability that the difference between the sample mean and the true mean is larger than a given $\epsilon$ converges to zero as the sample size grows, for all $\epsilon > 0 $.

\subsubsection{Chernoff Bounds}\label{chernoff}

The Chernoff bound describes exponentially decreasing bounds on tail distributions of sums of indenpendent random variables. It is a sharper bound than Markov's ineqaulity and Chebyshev's inequlaity. 

We use the Chernoff bound since we would like to have sharper bounds for $ P( X - E[X] \geq t) $. 

The Chernoff bound for a random variable $X$ is attained by applying the exponential function:

$$ P( X - E[X] \geq t )  = P( e^{\lambda(X- E[X])} \geq e^{\lambda t)}) \leq \frac{E [\text{exp}(\lambda(X- E[X])]}{\text{exp}(\lambda t)}$$

For any $\lambda > 0 $.  The function $E[e^{tX}]$ of the random variable $X$ is called the \textbf{moment generating function}.  So the probability that $X$ exceeds it's expected value by $t$ is bound by the moment generating function. We can now bound the moment generating function and optimise the bound in $lambda$. 

\underline{Example} 

Taking a random variable $X \sim N(0,1) $ we want to derive $P(X \geq t)$. The moment generating function is $e^{\lambda^2 / 2}$. We therefore have 

$$ P(X \geq t) \leq \frac{e^{\lambda ^2 / 2}}{e^{\lambda t}} = \text{exp}(\lambda^2 / 2 - \lambda t)$$

Optimizing this w.r.t $\lambda$ we get that $\lambda = t$.

\textbf{Why did we do this???} 

\subsection{Back to the Discussion of the Mean Estimator}

Having discussed these bounds, we can now apply them to find bounds for the mean estimator discussed before. 

\end{document}
